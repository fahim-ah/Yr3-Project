{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Year 3 project - Optimising the stability of a catalyst**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading + imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     # pip install pandas\n",
    "import matplotlib.pyplot as plt     # pip install matplotlib\n",
    "from sklearn.cluster import KMeans      # pip install scikit-learn\n",
    "from matminer.featurizers.conversions import StrToComposition       # pip install matminer\n",
    "from pymatgen.ext.matproj import MPRester       # pip install pymatgen\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display     # pip install display\n",
    "from mp_api.client import MPRester      # pip install mp-api\n",
    "from pymatgen.analysis.pourbaix_diagram import PourbaixDiagram\n",
    "from pymatgen.analysis.pourbaix_diagram import PourbaixPlotter\n",
    "\n",
    "# Reading initial dataset & displaying\n",
    "initial_df = pd.read_csv(r'Python import.csv')\n",
    "display(initial_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to explore the dataset, find column names, any null values etc...\n",
    "def dataset_info(dataset):\n",
    "    print(dataset.columns)\n",
    "    print(dataset.describe())\n",
    "    print(dataset.info())\n",
    "    display(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will replace '-' values for zeroes. Also replace Nan values with zeroes\n",
    "def parse_Nan(dataset):\n",
    "    parse_datatset = dataset.replace('-',0) \n",
    "    parse_datatset = parse_datatset.fillna(0)\n",
    "    return parse_datatset\n",
    "#This function will count all the zeroes in the dataframe\n",
    "def count_zeroes(df):\n",
    "    return (df == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will filter columns that are required for us. Also convert some object columns to floats\n",
    "def column_cleaning(dataset):\n",
    "    columns_to_keep = [\"Catalyst Materials\",\"Family\",\"ΔGOH*\",\"ΔGO*\",\"ΔGOOH*\",\"Overpotential at xx (nearby) current density vs RHE, V\",\"Reaction (HER, HRR, OER, ORR)\"]\n",
    "    updated_data = dataset.loc[:,columns_to_keep]\n",
    "    columns_to_int = [\"ΔGOH*\",\"ΔGO*\",\"ΔGOOH*\",\"Overpotential at xx (nearby) current density vs RHE, V\"]\n",
    "    updated_data[columns_to_int] = updated_data[columns_to_int].astype(float)\n",
    "    return updated_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Launching cleaning functions on datasets + further exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launching functions\n",
    "initial_df = parse_Nan(initial_df)\n",
    "zeroes_df = count_zeroes(initial_df)\n",
    "display(zeroes_df) \n",
    "updated_data = column_cleaning(initial_df)\n",
    "\n",
    "# Finding information on catalyst families and reaction types \n",
    "print(updated_data['Family'].value_counts())\n",
    "print(updated_data['Reaction (HER, HRR, OER, ORR)'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding reaction pathway energy differences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin to compare the two reaction pathways to determine which one to use\n",
    "\n",
    "updated_data['ΔGO*-ΔGOH*'] = updated_data['ΔGO*'] - updated_data['ΔGOH*']\n",
    "updated_data['ΔGOOH*-ΔGO*'] = updated_data['ΔGOOH*'] - updated_data['ΔGO*']\n",
    "\n",
    "#Slicing only data with values for required columns, then plotting dataset\n",
    "updated_data = updated_data.loc[updated_data[\"ΔGO*-ΔGOH*\"] != 0.0 ]\n",
    "\n",
    "# .describe() will give the mean of both pathways, hence can determine which one to use\n",
    "print(updated_data.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Element composition featurisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column for element composition\n",
    "str_comp = StrToComposition(target_col_id='composition')\n",
    "updated_data = str_comp.featurize_dataframe(updated_data, col_id='Catalyst Materials')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing material ID from material project + other properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This block will use an API key to gather material information from The Materials Project\n",
    "'formula='**O3'' gathers data for perovskites\n",
    "Data of interest that was retrieved include material_id and chemsys\n",
    "print(data_list) prints all the material properties possible to gather\n",
    "'''\n",
    "\n",
    "with MPRester('CmGarHKLtPCjVpEkivPDYkhRJKJiB8A7') as mpr:\n",
    "    results = mpr.summary.search(formula='**O3', fields=[\"material_id\", \"formula_pretty\",'band_gap','chemsys'])\n",
    "    data_list = [(result.material_id, result.formula_pretty, result.band_gap,result.chemsys) for result in results]\n",
    "    #print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Some formulae imported from The Materials project was not in the correct format\n",
    "e.g. AlGdO3 is in our dataset but in the API its given as GdAlO3\n",
    "This occurs often and doesnt allow our dataset to merge with the imported data\n",
    "Therefore this function rearranges the imported formulae to allow merge\n",
    "'''\n",
    "def alph_order(composition):\n",
    "    new_formula = []\n",
    "    for i in composition:\n",
    "        first= []\n",
    "        second= []\n",
    "        temp = list(i)\n",
    "        capital_pos=[]\n",
    "        for x in range(0, len(temp)):\n",
    "            if temp[x].isupper() == True:\n",
    "                capital_pos.append(x)\n",
    "        for y in range(capital_pos[0], capital_pos[1]):\n",
    "                first.append(temp[y])\n",
    "        for z in range(capital_pos[1], len(temp)):\n",
    "                second.append(temp[z])\n",
    "        first = ''.join(str(v) for v in first)\n",
    "        second = ''.join(str(v) for v in second)\n",
    "        compound = ''.join(str(v) for v in first)\n",
    "        compound = second+first+\"O3\"\n",
    "        new_formula.append(compound)\n",
    "    return new_formula\n",
    "\n",
    "#This function is to delete the extra O3 placed in the formulas\n",
    "\n",
    "def remove_O3(composition):\n",
    "    return [i.replace(\"O3\", \"\") for i in composition]\n",
    "\n",
    "def add_o3(composition):\n",
    "    return [i + \"O3\" for i in composition]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting list to a dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imported data is given as a list \n",
    "This block converts list into a dictionary format\n",
    "After dictionary is produced it is made into a pandas dataframe\n",
    "'''\n",
    "\n",
    "formula = []\n",
    "material_id = []\n",
    "band_gap = []\n",
    "chemsys = []\n",
    "for i in data_list:\n",
    "    material_id.append(i[0])\n",
    "    formula.append(i[1])\n",
    "    band_gap.append(i[2])\n",
    "    chemsys.append(i[3])\n",
    "#Creating dictionary\n",
    "material_proj_data = dict((z[0], list(z[1:])) for z in zip(formula, material_id, band_gap, chemsys))\n",
    "rearranged_formula = alph_order(formula)\n",
    "rearranged_formula = remove_O3(rearranged_formula)\n",
    "rearranged_formula = add_o3(rearranged_formula)\n",
    "#Creating dictionary for re-arranged formulae\n",
    "material_proj_data_rearranged = dict((z[0], list(z[1:])) for z in zip(rearranged_formula, material_id, band_gap, chemsys))\n",
    "material_proj_data.update(material_proj_data_rearranged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary to pandas dataframe + merge with original dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging imported data to our dataset\n",
    "\n",
    "material_proj_df = pd.DataFrame.from_dict(material_proj_data, orient= 'index')\n",
    "material_proj_df = material_proj_df.reset_index()\n",
    "material_proj_df.columns = [\"Catalyst Materials\", \"material id\", \"band gap\",\"chemsys\"]\n",
    "updated_data = updated_data.merge(material_proj_df, on ='Catalyst Materials', how= 'left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset exploration after importing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring data after importing new properties\n",
    "\n",
    "dataset_info(updated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing first graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function will plot the scatter plot for 'ΔGO*-ΔGOH*' against overpotential\n",
    "Plots for ΔGO* & ΔGOH* were produced to explore any anomalous data that could have occured\n",
    "'''\n",
    "\n",
    "def plot_scatter_reaction_path(data):\n",
    "    x_variables = ['ΔGO*-ΔGOH*','ΔGO*','ΔGOH*']\n",
    "    for i in x_variables:\n",
    "        plt.scatter(data[i],data[\"Overpotential at xx (nearby) current density vs RHE, V\"])\n",
    "        plt.xlabel(i+'(eV)')\n",
    "        plt.ylabel('Overpotential at xx (nearby) current density vs RHE (V)')\n",
    "        if i=='ΔGO*-ΔGOH*':\n",
    "            plt.title('Plot for overpotential against reaction pathway')\n",
    "            plt.savefig('Scatter_plots\\Overpotential against reaction step (GO-GOH).png',bbox_inches='tight')\n",
    "        elif i=='ΔGO*':\n",
    "            plt.savefig('Scatter_plots\\Overpotential against reaction step (GO).png',bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig('Scatter_plots\\Overpotential against reaction step (GOH).png',bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an elbow plot to determine how many cluster will be required for model\n",
    "\n",
    "def elbow_plot(elbow_data):\n",
    "    k_rng = range(1,10)\n",
    "    sse = []\n",
    "    for k in k_rng:\n",
    "        km = KMeans(n_clusters= k)\n",
    "        km.fit(elbow_data[['ΔGO*-ΔGOH*','Overpotential at xx (nearby) current density vs RHE, V']])\n",
    "        sse.append(km.inertia_)     # Calculates SSE for each cluster\n",
    "    print(sse)\n",
    "    plt.xlabel('Number of clusters, k')\n",
    "    plt.ylabel('Sum of squared error')\n",
    "    plt.title('Elbow plot for SSE against number of clusters')\n",
    "    plt.plot(k_rng,sse)\n",
    "    plt.savefig('Scatter_plots\\Elbow plot .png',bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating cluster plot using K-means method\n",
    "def cluster_df(cluster_df,n_clusters):\n",
    "    color = ['black','green','purple','red','blue']\n",
    "    for k in range(0,n_clusters):\n",
    "        data = cluster_df[cluster_df[\"cluster\"]==k]\n",
    "        plt.scatter(data['ΔGO*-ΔGOH*'],data[\"Overpotential at xx (nearby) current density vs RHE, V\"],c=color[k])\n",
    "        # Save datasets\n",
    "        if k==0:\n",
    "            data.to_csv('Cluster_csv_files\\Cluster_0.csv')\n",
    "        elif k==1:\n",
    "                data.to_csv('Cluster_csv_files\\Cluster_1.csv')\n",
    "        elif k==2:\n",
    "            data.to_csv('Cluster_csv_files\\Cluster_2.csv')\n",
    "        elif k==3:\n",
    "            data.to_csv('Cluster_csv_files\\Cluster_3.csv')\n",
    "        else:\n",
    "            data.to_csv('Cluster_csv_files\\Cluster_4.csv')\n",
    "    plt.xlabel('ΔGO*-ΔGOH* (eV)')\n",
    "    plt.ylabel('Overpotential at xx (nearby) current density vs RHE (V)')\n",
    "    plt.title('Plot for overpotential against reaction pathway [CLUSTERED]')\n",
    "    plt.savefig('Scatter_plots\\Overpotential against reaction step (with regions).png',bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    #Creates the same clusters in the linear regression models\n",
    "    \n",
    "    for k in range(0,n_clusters):\n",
    "        data = cluster_df[cluster_df[\"cluster\"]==k]\n",
    "        plt.scatter(data['ΔGOH*'],data['ΔGOOH*'],c=color[k])\n",
    "    plt.xlabel('ΔGOH* (eV)')\n",
    "    plt.ylabel('ΔGOOH* (eV)')\n",
    "    plt.title('Linear relationship between OH* & OOH*')\n",
    "    plt.savefig('Scatter_plots\\GOH against GOOH .png',bbox_inches='tight')\n",
    "    plt.show()\n",
    "    for k in range(0,n_clusters):\n",
    "        data = cluster_df[cluster_df[\"cluster\"]==k]\n",
    "        plt.scatter(data['ΔGO*'],data['ΔGOH*'],c=color[k])\n",
    "    plt.xlabel('ΔGO* (eV)')\n",
    "    plt.ylabel('ΔGOH* (eV)')\n",
    "    plt.title('Linear relationship between O* & OH*')\n",
    "    plt.savefig('Scatter_plots\\GO against GOH .png',bbox_inches='tight')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to form linear regression model\n",
    "def linear_regression_model(dataset,x,y):\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(dataset[[x]], dataset[[y]])\n",
    "    slope = reg.coef_[0][0]     # Calculates gradient of linear regression\n",
    "    print(slope)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placing functions down\n",
    "plot_scatter_reaction_path(updated_data)\n",
    "elbow_plot(updated_data)\n",
    "km = KMeans(n_clusters= 5)\n",
    "y_predicted = km.fit_predict(updated_data[['ΔGO*-ΔGOH*','Overpotential at xx (nearby) current density vs RHE, V']])\n",
    "updated_data['cluster'] = y_predicted\n",
    "cluster_df(updated_data,5)\n",
    "linear_regression_model(updated_data,'ΔGOH*','ΔGOOH*')\n",
    "linear_regression_model(updated_data,'ΔGO*','ΔGOH*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring data for each cluster**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-importing cluster dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all datasets and saving to a variable\n",
    "cluster_1 = pd.read_csv(r'Cluster_csv_files\\Cluster_0.csv')\n",
    "cluster_2 = pd.read_csv(r'Cluster_csv_files\\Cluster_1.csv')\n",
    "cluster_3 = pd.read_csv(r'Cluster_csv_files\\Cluster_2.csv')\n",
    "cluster_4 = pd.read_csv(r'Cluster_csv_files\\Cluster_3.csv')\n",
    "cluster_5 = pd.read_csv(r'Cluster_csv_files\\Cluster_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determining which cluster is assigned**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function to find minimum overpotential in a dataset\n",
    "The minimum will be used to keep a cluster variable consistent for the rest of the project\n",
    "This is because the cluster value changes every time the code is run\n",
    "'''\n",
    "def print_min(data):\n",
    "    print(data[\"Overpotential at xx (nearby) current density vs RHE, V\"].min())\n",
    "print_min(cluster_1)\n",
    "print_min(cluster_2)\n",
    "print_min(cluster_3)\n",
    "print_min(cluster_4)\n",
    "print_min(cluster_5)\n",
    "df_list = [cluster_1,cluster_2,cluster_3,cluster_4,cluster_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning clusters\n",
    "\n",
    "def assign_clusters(df_list):\n",
    "    for data in df_list:\n",
    "        if data[\"Overpotential at xx (nearby) current density vs RHE, V\"].min() == 1.89:\n",
    "            left_data = data\n",
    "        elif data[\"Overpotential at xx (nearby) current density vs RHE, V\"].min() == 1.09:\n",
    "            middle_left = data\n",
    "        elif data[\"Overpotential at xx (nearby) current density vs RHE, V\"].min() == 0.81:\n",
    "            middle_right = data\n",
    "        elif data[\"Overpotential at xx (nearby) current density vs RHE, V\"].min() == 0.26:\n",
    "            optimum_region = data\n",
    "        else:\n",
    "            right_data = data\n",
    "    new_df_list = [left_data,middle_left,middle_right,optimum_region,right_data]\n",
    "    return new_df_list\n",
    "\n",
    "new_df_list = assign_clusters(df_list)\n",
    "\n",
    "var_names = [\"left_data\", \"middle_left\", \"middle_right\", \"optimum_region\", \"right_data\"]\n",
    "vars_dict = dict(zip(var_names, new_df_list))\n",
    "left_data = vars_dict[\"left_data\"]\n",
    "middle_left= vars_dict[\"middle_left\"]\n",
    "middle_right = vars_dict[\"middle_right\"]\n",
    "optimum_region = vars_dict[\"optimum_region\"]\n",
    "right_data = vars_dict[\"right_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a spreadsheet for each cluster region\n",
    "\n",
    "with pd.ExcelWriter('separated regions.xlsx') as writer:  \n",
    "    left_data.to_excel(writer, sheet_name='left data')\n",
    "    middle_right.to_excel(writer, sheet_name='middle right')\n",
    "    middle_left.to_excel(writer, sheet_name='middle left')\n",
    "    optimum_region.to_excel(writer, sheet_name='optimum region')\n",
    "    right_data.to_excel(writer, sheet_name='right data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding composition data on each dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to produce a df of counts for every element within each region\n",
    "\n",
    "def retrieve_composition_df(df):\n",
    "    comp_list = list(df['composition'])\n",
    "    ind_element = []\n",
    "    for i in comp_list:\n",
    "        ind_element+=i.split()\n",
    "    [[x,ind_element.count(x)] for x in set(ind_element)]\n",
    "    ind_element_dic =  dict((x,ind_element.count(x)) for x in set(ind_element))\n",
    "    ind_element_df = pd.DataFrame.from_dict(ind_element_dic, orient = 'index', columns=['Count'])\n",
    "    ind_element_df= ind_element_df.reset_index(names=['Element'])\n",
    "    ind_element_df = ind_element_df.sort_values(by = 'Count', ascending=False, ignore_index=True)\n",
    "    return ind_element_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart plot to visualise the number of elements in each region, + saving figures\n",
    "\n",
    "def bar_chart_element_count(df1,df2,df3,df4,df5):\n",
    "    df_list = [df1,df2,df3,df4,df5]\n",
    "    for i in range(0,len(df_list)):\n",
    "        title_lst = ['Optimum region','Left side','Middle left','Middle right', 'Right side']\n",
    "        df = df_list[i].loc[1:12,:]\n",
    "        df = df[df.Element != 'O2']\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.bar(x=df['Element'], height=df['Count'])\n",
    "        ax.set_title(title_lst[i])\n",
    "        ax.set_xlabel('Element')\n",
    "        ax.set_ylabel('Count')\n",
    "        fig.savefig('Bar_charts\\\\'+title_lst[i]+'.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching the two functions from above\n",
    "\n",
    "element_df_optimum =  retrieve_composition_df(optimum_region)\n",
    "element_df_left =  retrieve_composition_df(left_data)\n",
    "element_df_middle_left =  retrieve_composition_df(middle_left)\n",
    "element_df_middle_right =  retrieve_composition_df(middle_right)\n",
    "element_df_right =  retrieve_composition_df(right_data)\n",
    "#bar_chart_element_count(element_df_optimum,element_df_left,element_df_middle_left,element_df_middle_right,element_df_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysing if elements are spread or concentrated in one region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following blocks will create a new excel spreadsheet which counts each element in every region (Appendix 3 in report)\n",
    "\n",
    "#Adding new column names\n",
    "title_lst = ['Optimum region','Left side','Middle left','Middle right', 'Right side']\n",
    "element_df_optimum['Region'] = 'Optimum region'\n",
    "element_df_left['Region'] = 'Left side'\n",
    "element_df_middle_left['Region'] =  'Middle left'\n",
    "element_df_middle_right['Region'] = 'Middle right'\n",
    "element_df_right['Region'] = 'Right side'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining datasets \n",
    "combined_element_df = pd.concat([element_df_optimum,element_df_left,element_df_middle_left,element_df_middle_right,element_df_right])\n",
    "combined_element_df = combined_element_df.pivot_table(\n",
    "                        values='Count',\n",
    "                        index='Element',\n",
    "                        columns='Region',\n",
    "                        fill_value=0,\n",
    "                        aggfunc= sum,\n",
    "                        margins=True)\n",
    "#combined_element_df.to_excel('Element analysis file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove rows which will not get us data from the materials project\n",
    "# If the material does not have a material id, a pourbaix diagram cannot be generated\n",
    "def remove_rows_without_data(datset):\n",
    "    df = datset.dropna(subset = ['material id'], inplace = False)\n",
    "    return df\n",
    "df_list = [optimum_region,middle_left,middle_right,left_data,right_data]\n",
    "left_data_pourbaix = remove_rows_without_data(left_data)\n",
    "right_data_pourbaix = remove_rows_without_data(right_data)\n",
    "middle_left_pourbaix = remove_rows_without_data(middle_left)\n",
    "middle_right_pourbaix = remove_rows_without_data(middle_right)\n",
    "optimum_region_pourbaix = remove_rows_without_data(optimum_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for Generating pourbaix diagrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A repeatable function to generate a pourbaix diagram\n",
    "# Input equals to the chemical composition and a path to save the figure\n",
    "\n",
    "def generate_pourbaix(chemsys,path):\n",
    "    with MPRester(api_key='CmGarHKLtPCjVpEkivPDYkhRJKJiB8A7') as mpr:\n",
    "        pourbaix_entries = mpr.get_pourbaix_entries(chemsys)\n",
    "    pd = PourbaixDiagram(pourbaix_entries)\n",
    "    plotter = PourbaixPlotter(pd)\n",
    "    PourbaixPlotter.get_pourbaix_plot(plotter,limits=[[-2, 16],[-3, 3]]) # Typical value for lower = -2, upper = 16\n",
    "    plt.savefig(path+chemsys+'.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gathering 10 random samples from each region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Finding 10 random formulas from each region\n",
    "   Uncomment following lines to generate new random samples from each region\n",
    "'''\n",
    "# rand_opt_region = random.sample(list(optimum_region_pourbaix['chemsys']), 10)\n",
    "# rand_middle_left = random.sample(list(middle_left_pourbaix['chemsys']), 10)\n",
    "# rand_middle_right = random.sample(list(middle_right_pourbaix['chemsys']), 10)\n",
    "# rand_left = random.sample(list(left_data_pourbaix['chemsys']), 10)\n",
    "# rand_right = random.sample(list(right_data_pourbaix['chemsys']), 10)\n",
    "\n",
    "\n",
    "# Random samples generated when running the above code for the first time \n",
    "rand_opt_region = ['Cd-Mn-O', 'O-Rh-Tb', 'Lu-Mn-O', 'Fe-Lu-O', 'La-O-Ti', 'Ba-Mn-O', 'Cr-O-Sr', 'Ca-O-Ru', 'Mn-Nd-O', 'Fe-Nd-O']\n",
    "rand_middle_left = ['Cr-Ho-O', 'O-Pb-V', 'Na-O-Pu', 'Dy-O-V', 'K-O-Os', 'Nb-O-Yb', 'La-O-Ta', 'O-Sm-V', 'Cd-O-V', 'K-O-Ta']\n",
    "rand_middle_right = ['Bi-Ho-O', 'Ba-Bi-O', 'Ho-Ni-O', 'Cu-La-O', 'Au-Ba-O', 'Cs-I-O', 'Lu-Ni-O', 'Al-O-Yb', 'Dy-Ni-O', 'Ba-Cu-O']\n",
    "rand_left = ['Ba-Mo-O', 'In-O-Ta', 'Na-O-W', 'Ca-O-W', 'Al-Ba-O', 'O-Tl-W', 'Ba-Nb-O', 'O-Sc-Si', 'Mo-Na-O', 'O-Sr-V']\n",
    "rand_right = ['Al-Gd-O', 'Ba-O-Zr', 'O-Sr-Ti', 'O-Sc-Yb', 'Ba-O-Sc', 'In-Nd-O', 'Cu-O-Y', 'O-Pb-Sr', 'Eu-Ge-O', 'Ba-In-O']\n",
    "\n",
    "#Function to generate pourbaix diagrams through each list\n",
    "def list_screening(lst,index):\n",
    "    path_name = ['Pourbaix_plots\\Optimum_region\\\\','Pourbaix_plots\\Middle_left\\\\','Pourbaix_plots\\Middle_right\\\\',\n",
    "                'Pourbaix_plots\\Left_data\\\\','Pourbaix_plots\\Right_data\\\\']\n",
    "    for i in range(0,len(lst)):\n",
    "        generate_pourbaix(lst[i],path_name[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating pourbaix diagrams for random elements selected\n",
    "\n",
    "list_screening(rand_opt_region,0)\n",
    "list_screening(rand_middle_left,1)\n",
    "list_screening(rand_middle_right,2)\n",
    "list_screening(rand_left,3)\n",
    "list_screening(rand_right,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing single element pourbaix to multi element**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will focus on the effects of noble metals\n",
    "\n",
    "generate_pourbaix('Ag-Ru-O','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Ag-Ru','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Ag','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Ag-O','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Ru','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Ru-O','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will focus on the effects of lanthanides\n",
    "\n",
    "generate_pourbaix('Fe-Nd-O','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Fe-Nd','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Fe','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Fe-O','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Nd','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n",
    "generate_pourbaix('Nd-O','Pourbaix_plots\\Comapring_single_and_multi\\\\')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lanthanide series analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block will generate the lanthanide pourbaix diagrams for the whole series.\n",
    "\n",
    "# List of lanthanides\n",
    "lanth_list = ['Ce','Dy', 'Er', 'Eu', 'Gd', 'Ho', 'La', 'Lu', 'Nd', 'Pr', 'Sm', 'Tb', 'Tm', 'Yb']\n",
    "\n",
    "# Looping over list and generating pourbaix diagram\n",
    "for i in range(0,len(lanth_list)):\n",
    "    generate_pourbaix(lanth_list[i],'Pourbaix_plots\\Lanthanides\\\\')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba9d6d80d2d4940eb0c1c06aa984546225b073a21b65076120add7de741b0a88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
